# Example Feature Engineering Pipeline Configuration
# This file demonstrates how to configure the feature extraction and dataset generation pipeline

# Dataset generation configuration
dataset_name: example_feature_dataset_001
output_directory: data/features

# Labeling configuration
labeling:
  strategy: rank_based  # Options: absolute, rank, binary, multiclass, optimal
  algorithm: single_anchor  # TSP algorithm to use for labeling
  top_k_percent: 10.0  # For binary classification: top 10% labeled as positive
  random_seed: 42

# Feature extraction configuration
feature_extraction:
  # List of feature extractors to use
  # Options: weight, topological_minimal, topological_full, mst, neighborhood, heuristic, graph_context
  extractors:
    - weight
    - topological_minimal  # Excludes expensive betweenness centrality
    - mst
    - neighborhood
    - heuristic
    - graph_context

  # Neighborhood extractor configuration
  neighborhood_params:
    k_values: [1, 2, 3, 5]
    density_percentiles: [25, 50, 75]
    n_shells: 3

# Pipeline configuration
pipeline:
  validate_features: true
  show_progress: true
  save_intermediate: true

  # Caching configuration
  use_cache: true
  cache_dir: data/cache/features

  # Graph metadata to include
  include_metadata:
    - graph_type
    - graph_size
    - weight_range
    - metricity_score

# Feature selection configuration (optional post-processing)
feature_selection:
  enabled: false
  method: correlation  # Options: correlation, f_test, mutual_info, rfe, model_based, l1, variance
  k: 20  # Number of features to select
  remove_correlated: true
  correlation_threshold: 0.95

# Feature transformation configuration (optional post-processing)
feature_transformation:
  enabled: false
  standardization: zscore  # Options: zscore, minmax, robust, null

  # Non-linear transformations
  transformations:
    # Example: apply log transform to skewed features
    # weight_based.mean_weight: log
    # weight_based.total_weight: log

  # Feature interactions
  interactions:
    # Example: create product features
    # - [weight_based.min_weight, mst_based.mst_degree, product]
    # - [topological.closeness_centrality, mst_based.mst_degree, product]

  # Binning configuration
  binning:
    # Example: discretize continuous features
    # weight_based.mean_weight: quantile

  n_bins: 5
  polynomial_degree: 2
  handle_zeros: offset  # Options: offset, replace, skip

# Output configuration
output:
  format: csv  # Options: csv, pickle, both
  include_raw_features: true
  include_transformed_features: false
  save_metadata: true

# Graph collection to process
# This would reference a previously generated batch
input_graphs:
  directory: data/graphs
  pattern: "*.npz"  # Match all graph files
  limit: null  # Process all graphs, or set a limit for testing

  # Optional: provide known optimal weights for relative labeling
  optimal_weights: null  # Path to JSON file with {graph_id: optimal_weight}

# Example usage:
# 1. Generate graphs using example_batch_config.yaml
# 2. Configure feature extraction with this file
# 3. Run: python scripts/extract_features.py --config config/feature_config_example.yaml
# 4. Output: data/features/example_feature_dataset_001.csv
